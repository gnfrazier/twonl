{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import arrow\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import photo as pto\n",
    "import podcast as pc\n",
    "import twitter as twit\n",
    "\n",
    "# Functions to manage the archive file\n",
    "\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "def get_archive():\n",
    "    '''Loads archive.json, or creates a new blank files structure.'''\n",
    "\n",
    "    # Load the archive file\n",
    "    try:\n",
    "        with open('archive.json', 'r') as file:\n",
    "            archive = json.loads(file.read())\n",
    "        print('Archive loaded.')\n",
    "\n",
    "    except:\n",
    "        # Create archive data structure.\n",
    "\n",
    "        archive = {'meta': {'ids': [],\n",
    "                            'audio': [],\n",
    "                            'tw_ids': [],\n",
    "                            'last_updated': 'New File',\n",
    "                            },\n",
    "                   'data': [],\n",
    "                   }\n",
    "        print('No archived file, building new archive.json')\n",
    "\n",
    "    return archive\n",
    "\n",
    "\n",
    "def save_archive(archive):\n",
    "    '''Saves to archive.json.'''\n",
    "\n",
    "    with open('archive.json', 'w') as file:\n",
    "        archive['meta']['last_updated'] = str(arrow.now())\n",
    "        file.write(json.dumps(archive, indent=4))\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_tweet_archive(record='tweets'):\n",
    "    '''Utility function to load the tweet archvive'''\n",
    "\n",
    "    filename = record + '.json'\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            archive = json.loads(file.read())\n",
    "        print('tweets_loaded.')\n",
    "\n",
    "    except:\n",
    "\n",
    "        print('No archived tweet file: ', filename,\n",
    "              ' build a new file with build_twitter_archive function')\n",
    "\n",
    "    return archive\n",
    "\n",
    "\n",
    "def backfill_dates(archive):\n",
    "    '''Helper function to convert timestamps\n",
    "    to a date. Date is used to match audio files to photos.'''\n",
    "\n",
    "    for walk in archive['data']:\n",
    "\n",
    "        timestamp = walk['timestamp']\n",
    "\n",
    "        date = timestamp.split(' ')[0]\n",
    "\n",
    "        walk['date'] = date\n",
    "\n",
    "    return archive\n",
    "\n",
    "\n",
    "def sort_archive_data(archive):\n",
    "    '''Sorts the data portion of archvie by date'''\n",
    "    \n",
    "    df = pd.DataFrame(archive['data'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', axis=1, inplace=True)\n",
    "    sorted_data = df.to_dict('records')\n",
    "    archive['data'] = sorted_data\n",
    "    \n",
    "    return archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive loaded.\n"
     ]
    }
   ],
   "source": [
    "archive = get_archive()\n",
    "full_keys = list(archive['data'][-1].keys())\n",
    "\n",
    "set_of_keys = {'link',\n",
    " 'condition',\n",
    " 'tag',\n",
    " 'temp',\n",
    " 'sun',\n",
    " 'raw_title',\n",
    " 'photo_id',\n",
    " 'thumb',\n",
    " 'camera',\n",
    " 'timestamp',\n",
    " 'date',\n",
    " 'user',\n",
    " 'fullname',\n",
    " 'url',\n",
    " 'text',\n",
    " 'replies',\n",
    " 'retweets',\n",
    " 'likes',\n",
    " 'tw_title',\n",
    " 'photo_link',\n",
    " 'wind',\n",
    " 'walk',\n",
    " 'tw_id',\n",
    " 'tw_timestamp'} # output of full_keys hardcoded into a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['meta', 'data'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-04-20T10:30:44.312229+00:00'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive['meta']['last_updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_records = []\n",
    "\n",
    "for record in archive['data']:\n",
    "    if len(set_of_keys) > len(record.keys()):\n",
    "        partial_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(partial_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_dates = []\n",
    "\n",
    "for item in partial_records:\n",
    "    partial_dates.append(item['date'])\n",
    "\n",
    "len(set(partial_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "def sort_archive_data(archive):\n",
    "    '''Sorts the data portion of archvie by date'''\n",
    "    \n",
    "    df = pd.DataFrame(archive['data'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', axis=1, inplace=True)\n",
    "    sorted_data = df.to_dict('records')\n",
    "    archive['data'] = sorted_data\n",
    "    \n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('date', inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "sorted_data = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'camera': 'BlackBerry 9000',\n",
       " 'condition': 'light breeze',\n",
       " 'date': '2011-06-16',\n",
       " 'fullname': 'Nathan Lowell',\n",
       " 'likes': 1.0,\n",
       " 'link': 'https://c1.staticflickr.com/3/2744/5838701745_1b899c9ecc_o.jpg',\n",
       " 'photo_id': '5838701745',\n",
       " 'photo_link': 'http://twitpic.com/5caxbx',\n",
       " 'raw_title': 'All sizes | #tommw 62F ptly cloudy, light breeze | Flickr - Photo Sharing!',\n",
       " 'replies': 0.0,\n",
       " 'retweets': 0.0,\n",
       " 'sun': 'ptly cloudy',\n",
       " 'tag': '#tommw',\n",
       " 'temp': '62',\n",
       " 'text': '#tommw 62F ptly cloudy, light breeze http://twitpic.com/5caxbx',\n",
       " 'thumb': 'images/5838701745.jpg',\n",
       " 'timestamp': '2011-06-16 06:10:35',\n",
       " 'tw_id': '81333156376096768',\n",
       " 'tw_timestamp': '2011-06-16 12:11:50',\n",
       " 'tw_title': '#tommw 62F ptly cloudy, light breeze http://twitpic.com/5caxbx',\n",
       " 'url': '/nlowell/status/81333156376096768',\n",
       " 'user': 'nlowell',\n",
       " 'walk': 1.0,\n",
       " 'wind': 'light breeze'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive['data'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_archive(archive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
