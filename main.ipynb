{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Walks of Nathan Lowell\n",
    "A look at Nate's path to the back gate.\n",
    "\n",
    "The journey begins [#tommw](https://www.nathanlowell.com/tommw/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import json\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import arrow\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import photo as pto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[#tommw](https://www.nathanlowell.com/tommw/) is a cross channel social media campaign architeched and executed by science fiction author Nathan Lowell. \n",
    "\n",
    "There are 4 planks to Nathan's campain:\n",
    "1. A blog hosted at https://www.nathanlowell.com/tommw/\n",
    "2. A photo stream hosted on [FlickR](https://www.flickr.com/photos/nlowell/)\n",
    "3. Podcast feed via [RSS](http://www.nathanlowell.com/tommw/feed/)\n",
    "4. Posts to twitter with the #tommw hastag on [@nlowell on twitter](https://twitter.com/nlowell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_archive():\n",
    "\n",
    "    # Load the archive file\n",
    "    try:\n",
    "        with open('archive.json', 'r') as file:\n",
    "            archive= json.loads(file.read())\n",
    "        print('Archive loaded.')\n",
    "        \n",
    "    except:\n",
    "        # Create archive data structure.\n",
    "\n",
    "        archive = {'meta':{'ids':[],\n",
    "                          'last_updated':'New File',\n",
    "                          },\n",
    "                  'data':[],\n",
    "                  }\n",
    "        print('No archived file, building new archive.json')\n",
    "        \n",
    "    return archive\n",
    "# Scrape the blog for links to the other media components\n",
    "blog_page = requests.get(\"https://www.nathanlowell.com/tommw/\")\n",
    "soup = BeautifulSoup(blog_page.text, 'html.parser')\n",
    "\n",
    "# Find a flickr link\n",
    "flickr = soup.find_all(href=True, attrs={'data-flickr-embed':'true'})\n",
    "\n",
    "if not flickr:\n",
    "    print('No flickr links found on blog home page.')\n",
    "    flicker_link = None\n",
    "    \n",
    "else:\n",
    "    flickr_link = flickr[0]['href']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_photo_stream_page(stream, archive=None):\n",
    "    \n",
    "    if not archive:\n",
    "        archive = get_archive()\n",
    "    \n",
    "    for photo in stream:\n",
    "        image_name = photo.split('/')[-1]\n",
    "        photo_id = image_name.split('_')[0]\n",
    "\n",
    "        if photo_id in archive['meta']['ids']:\n",
    "            # skip photos already recorded\n",
    "            continue\n",
    "\n",
    "        # Save the thumb size image\n",
    "        thumb_name = 'images/' + photo_id + '.jpg'\n",
    "        image = requests.get(photo, stream=True)\n",
    "        \n",
    "        \n",
    "        with open(thumb_name, 'wb') as image_file:\n",
    "            shutil.copyfileobj(image.raw, image_file)\n",
    "\n",
    "        # Only the original has EXIF data\n",
    "        info = pto.get_original_photo(photo_id)\n",
    "        \n",
    "        # Format the EXIF data\n",
    "        if info:\n",
    "            info['photo_id'] = photo_id\n",
    "            info['thumb'] = thumb_name\n",
    "            p_url = info.get('link')\n",
    "            if p_url:\n",
    "                camera, timestamp = pto.get_exif(p_url)\n",
    "            else:\n",
    "                camera, timestamp = ('Error', 'Error' )\n",
    "            info['camera'] = camera\n",
    "            info['timestamp'] = timestamp\n",
    "            archive['data'].append(info)\n",
    "            archive['meta']['ids'].append(photo_id)\n",
    "            archive['meta']['last_updated'] = str(arrow.now())\n",
    "            print(photo_id + ' added')\n",
    "\n",
    "        else:\n",
    "            print('no #tommow tag found')\n",
    "            \n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No archived file, building new archive.json\n",
      "https://www.flickr.com/photos/nlowell/page1\n",
      "32497027918 added\n",
      "45427063755 added\n",
      "46313540081 added\n",
      "45538428704 added\n",
      "32390140018 added\n",
      "31253793227 added\n",
      "46180203671 added\n",
      "32292571558 added\n",
      "31207048157 added\n",
      "46117344171 added\n",
      "44213546090 added\n",
      "45104952125 added\n",
      "32116506418 added\n",
      "44077082110 added\n"
     ]
    }
   ],
   "source": [
    "# Future Main\n",
    "archive = get_archive()\n",
    "\n",
    "if len(archive['meta']['ids']) < 1000:\n",
    "    archive = pto.build_flickr_archive(flickr_link, archive)\n",
    "    pass\n",
    "\n",
    "#stream_url = pto.get_stream_url(flickr_link)\n",
    "stream = pto.get_photostream(stream_url)\n",
    "archive = pto.process_photo_stream_page(stream, archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('archive.json', 'w') as file:\n",
    "    file.write(json.dumps(archive, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive File Structure\n",
    "\n",
    "``` python\n",
    "{'id':'123456789','info':{'timestamp':'2018-12-10 10:21', ...}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive['meta']['ids'].append('test_id')\n",
    "archive['meta']['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'https://www.flickr.com/photos/nlowell/page14'\n",
    "archive = get_archive()\n",
    "stream = pto.get_photostream(test)\n",
    "archive = process_photo_stream_page(stream, archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'this is. a test'\n",
    "title.find('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not archive:\n",
    "    archive = get_archive()\n",
    "\n",
    "for photo in stream:\n",
    "    image_name = photo.split('/')[-1]\n",
    "    photo_id = image_name.split('_')[0]\n",
    "\n",
    "    if photo_id in archive['meta']['ids']:\n",
    "        # skip photos already recorded\n",
    "        continue\n",
    "\n",
    "    # Save the thumb size image\n",
    "    thumb_name = 'images/' + photo_id + '.jpg'\n",
    "    image = requests.get(photo, stream=True)\n",
    "\n",
    "\n",
    "    with open(thumb_name, 'wb') as image_file:\n",
    "        shutil.copyfileobj(image.raw, image_file)\n",
    "\n",
    "    # Only the original has EXIF data\n",
    "    info = pto.get_original_photo(photo_id)\n",
    "\n",
    "    # Format the EXIF data\n",
    "    if info:\n",
    "        info['photo_id'] = photo_id\n",
    "        info['thumb'] = thumb_name\n",
    "        p_url = info.get('link')\n",
    "        if p_url:\n",
    "            camera, timestamp = pto.get_exif(p_url)\n",
    "        else:\n",
    "            camera, timestamp = ('Error', 'Error' )\n",
    "        info['camera'] = camera\n",
    "        info['timestamp'] = timestamp\n",
    "        archive['data'].append(info)\n",
    "        archive['meta']['ids'].append(photo_id)\n",
    "        archive['meta']['last_updated'] = str(arrow.now())\n",
    "        print(photo_id + ' added')\n",
    "\n",
    "    else:\n",
    "        print('no #tommow tag found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
